---
output:
  html_document:
    theme: cerulean
    highlight: tango
    code_folding: hide
    toc: yes
    toc_float: no
  pdf_document:
    number_sections: yes
geometry: margin = 1.2in
fontsize: 10pt
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,error=TRUE)


knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
)
```



```{r echo=FALSE}
#https://community.rstudio.com/t/showing-only-the-first-few-lines-of-the-results-of-a-code-chunk/6963/2
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
``` 

# Working with JSON

```{r}
library(tidyverse)
```


```{r, error=TRUE}
library(jsonlite)
yelp <- fromJSON("data/yelp_academic_dataset_business.json")
```
However, when we run the above command we would actully get an error like below.

This is because this JSON file turned out to be something called ‘NDJSON (Newline delimited JSON)’, which means there are multiple JSON values inside this file and each of the JSON values is considered as an independent object. In this particular case, each business information makes up one single JSON value therefore there are many JSON values inside of this JSON file. This could be used often in data streaming situations where each JSON data can be separated from other parts of the file so that each JSON data can be processed without waiting for the whole document to load.



```{r,message=FALSE, warning=FALSE, r,output.lines=10}
yelp <- stream_in(file("data/yelp_academic_dataset_business.json"))
```

Flatten Yelp data frame
Let’s find out how the data has been imported by quickly running ‘str()’ function.
```{r,output.lines=1:15}
str(yelp)
```
As you can see ‘hours’ variable is actually a data frame that contains 7 data frames each of which is for a weekday like ‘Tuesday’. And the weekday variables themselves are data frames and each contains two ‘character’ variables of ‘open’ and ‘close’.

This is reflecting the original JSON data structure, but it is a bit confusing for analyzing data in R. We can use ‘flatten()’ function from ‘jsonlite’ package to make the nested hiearchical data structure into a flatten manner by assigning each of the nested variable as its own column as much as possible.


```{r,output.lines=10}
yelp_flat <- jsonlite::flatten(yelp)
str(yelp_flat)
```


Now the data structure looks a lot easier to grasp and even the data looks easier to see.

Before printing out the data I’m going to use ‘as_data_frame()’ function from the new package called ‘tibble’, which was released just last week from Hadley Wickham and the team to make it easier to see the data frame data in R console UI.

We can use ‘as_data_frame()’ function to convert our data frame to be ‘tbl_df’, which is an extended version of the data frame. Once it’s in ‘tbl_df’ type, it automatically shows only the first 10 variables in the console output by simply typing the data frame name so you don’t need to call ‘head()’ function separately. Also, it shows a data type for each variable in the output.

```{r}
library(tibble)
yelp_tbl <- as_data_frame(yelp_flat)
yelp_tbl
```

```{r}
yelp_tbl2<-yelp_tbl %>% mutate(categories = as.character(categories)) %>% select(categories)
```


Drop now when you look at the data again, looks there are bunch of variables whose name starts with either ‘hours’ or ‘attributes’.

```{r}
yelp_tbl %>% 
 select(-starts_with("hours"), -starts_with("attribute"))
```

# Count how restaurants
Now, let’s find out how many ‘Restaurant’ business in the data. We can use ‘str_detect()’ function from ‘stringr’ package to find the businesses whose ‘categories’ variable values contain ‘Restaurant’ text. If you want to know more detail about this function check out this post.

```{r}
library(stringr)
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant"))
```
The cool thing about this function is that even when we have a ‘list’ data type variable it can go inside the list values and do the text matching. Pretty awesome.

Now, number of the rows is 21,892, as opposed to the original of 61,184 rows. That means there are 21,892 ‘Restaurant’ related businesses in this data out of 61,184 businesses. To confirm if this is really the case, let’s look at the categories column with ‘as.character()’ function again.

```{r}
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 mutate(categories = as.character(categories)) %>% select(categories)
```
Looks all the rows (well, all the first 10 rows anyway) look like they have “Restaurants’ as one of the categories.

And this is interesting because people on Yelp are tagging different genres for each “Restaurant” business. For example, some restaurants could be considered as “Bars”, “American (New)”, “Pub”, etc. So one of the interesting question would be, “what type of the restaurants are more common in this data set?”

The easiest way to answer this question is to break out this ‘categories’ list data type variable and assign each value inside the list into each row. So essentially we’ll have a variable called ‘categories’ and this will have just one category value for each row. This means, some businesses might be repeated across rows many times, but that’s ok because our concern for now is to count each restaurant category type.


# Unnest a list variable
To break out ‘categories’ variable and create one row for each value, we can use ‘unnest()’ function from tidyr package, which is another great package from ‘Hadleyverse’ to help making raw data into a ‘tidy’ format.

hadley/tidyr

tidyr - Easily tidy data with spread and gather functions.
github.com	
I will talk about more on ‘tidy’ format with ‘tidyr’ package in a separate post, but for now I am going to simply use ‘unnest()’ function to “unnest” the ‘categories’ variable like below.

```{r}
library(tidyr)
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 unnest(categories) %>%
 select(name, categories)
```



As you can see, ‘Emil’s Lounge’ is now repeated 5 times, for example. This is because it has those 5 different categories assigned to this business. This will allow us to do a quick summarization with ‘count()’ function like below.

```{r}
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 unnest(categories) %>%
 select(name, categories) %>%
 count(categories)
```



And if you want to see the top categories you can simply use ‘arrange()’ function to sort.

```{r}
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 unnest(categories) %>%
 select(name, categories) %>%
 count(categories) %>%
 arrange(desc(n))
```



Let’s get rid of the rows with ‘Restaurants’ category because we know every single rows in this data set has something to do with ‘Restaurant’ now.

```{r}
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 unnest(categories) %>%
 filter(categories != "Restaurants") %>%
 count(categories) %>%
 arrange(desc(n))
```


When you run the above command you will get something like below. You can see ‘Fast Food’ is the number one, and ‘Pizza’ and ‘Mexican’ come after.


What are the most common restaurant types per state / province?
In this data set, there is a variable called ‘state’ that contains state names or province names of US and some European countries. So, what if we want to know what restaurant categories are more frequently showing up for each state ?

We can simply add ‘state’ variable into ‘count()’ function like below.

```{r}
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 unnest(categories) %>%
 filter(categories != "Restaurants") %>%
 count(state, categories) %>%
 arrange(desc(n))
```



Now, let’s take a look at the top restaurant category for each state. We can use ‘group_by()’ function to group the data by state and use ‘top_n()’ function to keep only the top category. Both functions are from ‘dplyr’ package.

```{r}
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 unnest(categories) %>%
 filter(categories != "Restaurants") %>%
 count(state, categories) %>%
 group_by(state) %>%
 top_n(1, n)
```



As you can see there are 5 entries for “FIF” province, this is because they are all tie. But the values are just ‘1’ and that’s a really small number compared to the others. So let’s filter out those small numbers from the data before the group_by and top_n steps.

```{r}
yelp_tbl %>% select(-starts_with("hours"), -starts_with("attribute")) %>%
 filter(str_detect(categories, "Restaurant")) %>%
 unnest(categories) %>%
 filter(categories != "Restaurants") %>%
 count(state, categories) %>%
 filter(n > 10) %>%
 group_by(state) %>%
 top_n(1, n)
```



The result is a list of the top restaurant category for each of the 12 state or province.

This is a very simple analysis on Yelp business data. But given where we started with Yelp business data in the raw JSON format, hope this has demonstrated how quickly, incrementally, and iteratively we can get some interesting information out of such un-traditional (not tabular) data format relatively easily and quickly.

Notes: Adopted from https://blog.exploratory.io/working-with-json-data-in-very-simple-way-ad7ebcc0bb89